#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¢„åŠ è½½å†å² K çº¿æ•°æ®åˆ° Redis

ä» Binance/OKX API æ‹‰å–å†å² K çº¿æ•°æ®å¹¶å­˜å‚¨åˆ° Redisï¼Œä¾›ç­–ç•¥ä½¿ç”¨ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
    python preload_klines_to_redis.py [--days 60] [--interval 1m] [--exchange binance]
    python preload_klines_to_redis.py --exchange okx --days 60 --interval 1m
    python preload_klines_to_redis.py --exchange all --days 60  # åŒæ—¶åŠ è½½ä¸¤ä¸ªäº¤æ˜“æ‰€

ç¯å¢ƒå˜é‡ï¼š
    REDIS_HOST       - Redis ä¸»æœºåœ°å€ (é»˜è®¤: 127.0.0.1)
    REDIS_PORT       - Redis ç«¯å£ (é»˜è®¤: 6379)
    REDIS_PASSWORD   - Redis å¯†ç  (é»˜è®¤: ç©º)
    PROXY_HOST       - ä»£ç†ä¸»æœº (é»˜è®¤: 127.0.0.1)
    PROXY_PORT       - ä»£ç†ç«¯å£ (é»˜è®¤: 7890)

@author Sequence Team
@date 2026-01
"""

import os
import sys
import json
import time
import argparse
import requests
import redis
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==================== é…ç½® ====================

# Redis é…ç½®
REDIS_HOST = os.getenv("REDIS_HOST", "127.0.0.1")
REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))
REDIS_PASSWORD = os.getenv("REDIS_PASSWORD", "")

# Binance API é…ç½®
BINANCE_FUTURES_URL = "https://fapi.binance.com"
BINANCE_TESTNET_URL = "https://testnet.binancefuture.com"

# OKX API é…ç½®
OKX_API_URL = "https://www.okx.com"
OKX_TESTNET_URL = "https://www.okx.com"  # OKX æµ‹è¯•ç½‘ä½¿ç”¨ç›¸åŒåŸŸåï¼Œé€šè¿‡ header åŒºåˆ†

# æ¯æ‰¹æ¬¡æœ€å¤§æ•°é‡
BATCH_SIZE = 300  # OKX é™åˆ¶ 300ï¼ŒBinance é™åˆ¶ 1500

# å¹¶å‘çº¿ç¨‹æ•°
MAX_WORKERS = 3

# è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
REQUEST_DELAY = 0.5  # OKXé»˜è®¤å»¶è¿Ÿ
BINANCE_REQUEST_DELAY = 2.0  # Binanceéœ€è¦æ›´é•¿å»¶è¿Ÿï¼Œé¿å…418é”™è¯¯
BINANCE_LIST_TIME_DELAY = 3.0  # BinanceæŸ¥è¯¢ä¸Šçº¿æ—¶é—´çš„å»¶è¿Ÿï¼ˆæ›´é•¿ï¼Œé¿å…é™æµï¼‰


class BaseKlineLoader:
    """K çº¿æ•°æ®åŠ è½½å™¨åŸºç±»"""

    def __init__(self, use_proxy: bool = True):
        self.session = requests.Session()
        self.session.headers.update({
            "Content-Type": "application/json"
        })

        # ä»£ç†é…ç½®
        if use_proxy:
            proxy_host = os.getenv("PROXY_HOST", "127.0.0.1")
            proxy_port = os.getenv("PROXY_PORT", "7890")
            proxy_url = f"http://{proxy_host}:{proxy_port}"
            self.session.proxies = {
                "http": proxy_url,
                "https": proxy_url
            }
            print(f"[ä»£ç†] ä½¿ç”¨ä»£ç†: {proxy_url}")

    def get_exchange_info(self) -> List[str]:
        raise NotImplementedError

    def get_symbol_list_time(self, symbol: str) -> Optional[int]:
        """è·å–åˆçº¦ä¸Šçº¿æ—¶é—´ï¼ˆæ¯«ç§’æ—¶é—´æˆ³ï¼‰

        Returns:
            ä¸Šçº¿æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰ï¼Œå¦‚æœæ— æ³•è·å–åˆ™è¿”å›None
        """
        raise NotImplementedError

    def get_klines(self, symbol: str, interval: str, start_time: int, end_time: int, limit: int) -> List[Dict]:
        raise NotImplementedError

    @property
    def exchange_name(self) -> str:
        raise NotImplementedError

    @property
    def batch_size(self) -> int:
        return BATCH_SIZE


class BinanceKlineLoader(BaseKlineLoader):
    """Binance K çº¿æ•°æ®åŠ è½½å™¨"""

    def __init__(self, testnet: bool = False, use_proxy: bool = True):
        super().__init__(use_proxy)
        self.base_url = BINANCE_TESTNET_URL if testnet else BINANCE_FUTURES_URL
        self.testnet = testnet
        self._list_time_cache = {}  # ç¼“å­˜åˆçº¦ä¸Šçº¿æ—¶é—´

    @property
    def exchange_name(self) -> str:
        return "binance"

    @property
    def batch_size(self) -> int:
        return 1500

    def get_exchange_info(self) -> List[str]:
        """è·å–æ‰€æœ‰æ°¸ç»­åˆçº¦äº¤æ˜“å¯¹"""
        url = f"{self.base_url}/fapi/v1/exchangeInfo"
        try:
            response = self.session.get(url, timeout=30)
            if response.status_code == 200:
                data = response.json()
                symbols = []
                for sym in data.get("symbols", []):
                    if sym.get("contractType") == "PERPETUAL" and sym.get("status") == "TRADING":
                        symbols.append(sym["symbol"])
                return sorted(symbols)
        except Exception as e:
            print(f"[Binance] è·å–äº¤æ˜“å¯¹åˆ—è¡¨å¤±è´¥: {e}")
        return []

    def get_symbol_list_time(self, symbol: str) -> Optional[int]:
        """è·å–Binanceåˆçº¦ä¸Šçº¿æ—¶é—´

        é€šè¿‡APIæŸ¥è¯¢å†å²æœ€æ—©Kçº¿ï¼Œä½¿ç”¨è¾ƒé•¿å»¶è¿Ÿé¿å…é™æµ
        """
        # æ£€æŸ¥ç¼“å­˜
        if symbol in self._list_time_cache:
            return self._list_time_cache[symbol]

        try:
            # ä½¿ç”¨ä¸€ä¸ªå¾ˆæ—©çš„æ—¶é—´æˆ³ï¼ˆ2017-01-01ï¼ŒBinanceæˆç«‹æ—¶é—´ï¼‰ä½œä¸ºèµ·ç‚¹
            url = f"{self.base_url}/fapi/v1/continuousKlines"
            early_time = int(datetime(2017, 1, 1).timestamp() * 1000)
            current_time = int(datetime.now().timestamp() * 1000)

            params = {
                "pair": symbol,
                "contractType": "PERPETUAL",
                "interval": "1d",
                "startTime": early_time,
                "endTime": current_time,
                "limit": 1  # åªè·å–æœ€æ—©çš„1æ¡
            }

            # æ·»åŠ å»¶è¿Ÿï¼Œé¿å…é™æµ
            time.sleep(BINANCE_LIST_TIME_DELAY)

            response = self.session.get(url, params=params, timeout=30)
            if response.status_code == 200:
                data = response.json()
                if data and len(data) > 0:
                    # è¿”å›ç¬¬ä¸€æ¡Kçº¿çš„æ—¶é—´æˆ³
                    earliest_ts = int(data[0][0])
                    # ç¼“å­˜ç»“æœ
                    self._list_time_cache[symbol] = earliest_ts
                    return earliest_ts
            elif response.status_code == 418:
                # IPè¢«å°ç¦ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´åé‡è¯•ä¸€æ¬¡
                print(f"[Binance] {symbol} APIé™æµ(418)ï¼Œç­‰å¾…10ç§’åé‡è¯•...")
                time.sleep(10)
                response = self.session.get(url, params=params, timeout=30)
                if response.status_code == 200:
                    data = response.json()
                    if data and len(data) > 0:
                        earliest_ts = int(data[0][0])
                        self._list_time_cache[symbol] = earliest_ts
                        return earliest_ts
                else:
                    print(f"[Binance] {symbol} é‡è¯•åä»ç„¶å¤±è´¥ï¼Œè·³è¿‡ä¸Šçº¿æ—¶é—´æ£€æµ‹")
                    return None
        except Exception as e:
            print(f"[Binance] {symbol} è·å–ä¸Šçº¿æ—¶é—´å¤±è´¥: {e}")
        return None

    def get_klines(self, symbol: str, interval: str, start_time: int, end_time: int, limit: int = 1500) -> List[Dict]:
        """è·å– K çº¿æ•°æ®ï¼ˆå¸¦é‡è¯•å’Œ418é”™è¯¯å¤„ç†ï¼‰"""
        url = f"{self.base_url}/fapi/v1/continuousKlines"
        params = {
            "pair": symbol,
            "contractType": "PERPETUAL",
            "interval": interval,
            "startTime": start_time,
            "endTime": end_time,
            "limit": limit
        }

        max_retries = 3
        retry_delay = 2.0  # åˆå§‹é‡è¯•å»¶è¿Ÿ

        for attempt in range(max_retries):
            try:
                response = self.session.get(url, params=params, timeout=30)

                if response.status_code == 200:
                    data = response.json()
                    klines = []
                    for item in data:
                        if len(item) >= 6:
                            kline = {
                                "timestamp": item[0],
                                "open": float(item[1]),
                                "high": float(item[2]),
                                "low": float(item[3]),
                                "close": float(item[4]),
                                "volume": float(item[5]),
                                "symbol": symbol,
                                "exchange": "binance",
                                "interval": interval,
                                "type": "kline"
                            }
                            klines.append(kline)
                    return klines

                elif response.status_code == 418:
                    # IPè¢«ä¸´æ—¶å°ç¦
                    try:
                        error_data = response.json()
                        ban_until = error_data.get('msg', '')
                        print(f"[Binance] {symbol} IPè¢«å°ç¦: {ban_until}")
                    except:
                        print(f"[Binance] {symbol} IPè¢«å°ç¦ (418)")

                    if attempt < max_retries - 1:
                        wait_time = retry_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                        print(f"[Binance] {symbol} ç­‰å¾… {wait_time:.1f} ç§’åé‡è¯• (å°è¯• {attempt+1}/{max_retries})")
                        time.sleep(wait_time)
                        continue
                    else:
                        print(f"[Binance] {symbol} è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè·³è¿‡")
                        return []

                elif response.status_code == 429:
                    # è¯·æ±‚è¿‡äºé¢‘ç¹
                    print(f"[Binance] {symbol} è¯·æ±‚è¿‡äºé¢‘ç¹ (429)")
                    if attempt < max_retries - 1:
                        wait_time = retry_delay * (2 ** attempt)
                        print(f"[Binance] {symbol} ç­‰å¾… {wait_time:.1f} ç§’åé‡è¯•")
                        time.sleep(wait_time)
                        continue
                    else:
                        return []

                else:
                    print(f"[Binance] {symbol} API è¿”å› {response.status_code}: {response.text[:100]}")
                    return []

            except Exception as e:
                print(f"[Binance] {symbol} è·å– K çº¿å¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    continue
                return []

        return []


class OKXKlineLoader(BaseKlineLoader):
    """OKX K çº¿æ•°æ®åŠ è½½å™¨"""

    def __init__(self, testnet: bool = False, use_proxy: bool = True):
        super().__init__(use_proxy)
        self.base_url = OKX_API_URL
        self.testnet = testnet
        self._instruments_cache = None  # ç¼“å­˜instrumentsæ•°æ®
        self._list_time_cache = {}  # ç¼“å­˜åˆçº¦æ•°æ®èµ·å§‹æ—¶é—´
        if testnet:
            self.session.headers.update({
                "x-simulated-trading": "1"
            })

    @property
    def exchange_name(self) -> str:
        return "okx"

    @property
    def batch_size(self) -> int:
        return 300

    def _get_instruments_data(self) -> List[Dict]:
        """è·å–å¹¶ç¼“å­˜instrumentsæ•°æ®"""
        if self._instruments_cache is not None:
            return self._instruments_cache

        url = f"{self.base_url}/api/v5/public/instruments"
        params = {"instType": "SWAP"}
        try:
            response = self.session.get(url, params=params, timeout=30)
            if response.status_code == 200:
                data = response.json()
                if data.get("code") == "0":
                    self._instruments_cache = data.get("data", [])
                    return self._instruments_cache
        except Exception as e:
            print(f"[OKX] è·å–instrumentsæ•°æ®å¤±è´¥: {e}")
        return []

    def get_exchange_info(self) -> List[str]:
        """è·å–æ‰€æœ‰æ°¸ç»­åˆçº¦äº¤æ˜“å¯¹"""
        instruments = self._get_instruments_data()
        symbols = []
        for inst in instruments:
            inst_id = inst.get("instId", "")
            state = inst.get("state", "")
            # åªè·å– USDT æ°¸ç»­åˆçº¦ä¸”æ­£åœ¨äº¤æ˜“çš„
            if inst_id.endswith("-USDT-SWAP") and state == "live":
                symbols.append(inst_id)
        return sorted(symbols)

    def get_symbol_list_time(self, symbol: str) -> Optional[int]:
        """è·å–OKXåˆçº¦å®é™…æ•°æ®èµ·å§‹æ—¶é—´

        é€šè¿‡æ‹‰å–æœ€æ—©çš„Kçº¿æ¥ç¡®å®šçœŸå®çš„æ•°æ®èµ·å§‹æ—¶é—´ï¼Œè€Œä¸æ˜¯ä½¿ç”¨listTime
        å› ä¸ºlistTimeå¯èƒ½æ—©äºå®é™…å¼€å§‹äº¤æ˜“çš„æ—¶é—´

        Returns:
            å®é™…æ•°æ®èµ·å§‹æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰ï¼Œå¦‚æœæ— æ³•è·å–åˆ™è¿”å›None
        """
        # æ£€æŸ¥ç¼“å­˜
        if symbol in self._list_time_cache:
            return self._list_time_cache[symbol]

        try:
            # å°è¯•è·å–æœ€æ—©çš„Kçº¿æ•°æ®
            # ä½¿ç”¨ä¸€ä¸ªå¾ˆæ—©çš„æ—¶é—´æˆ³ï¼ˆ2020-01-01ï¼‰ä½œä¸ºèµ·ç‚¹
            url = f"{self.base_url}/api/v5/market/history-candles"
            early_time = int(datetime(2020, 1, 1).timestamp() * 1000)

            params = {
                "instId": symbol,
                "bar": "1D",  # ä½¿ç”¨1Då‘¨æœŸï¼Œæ›´å®¹æ˜“è·å–åˆ°æœ€æ—©æ•°æ®
                "after": str(early_time),
                "limit": "100"
            }

            response = self.session.get(url, params=params, timeout=30)
            if response.status_code == 200:
                data = response.json()
                if data.get("code") == "0":
                    candles = data.get("data", [])
                    if candles:
                        # OKXè¿”å›çš„æ•°æ®æ˜¯å€’åºçš„ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰ï¼Œæœ€åä¸€æ¡æ˜¯æœ€æ—©çš„
                        earliest_ts = int(candles[-1][0])
                        # ç¼“å­˜ç»“æœ
                        self._list_time_cache[symbol] = earliest_ts
                        return earliest_ts

        except Exception as e:
            print(f"[OKX] {symbol} è·å–å®é™…æ•°æ®èµ·å§‹æ—¶é—´å¤±è´¥: {e}")

        # å¦‚æœæ— æ³•é€šè¿‡Kçº¿è·å–ï¼Œå°è¯•ä½¿ç”¨listTimeä½œä¸ºfallback
        instruments = self._get_instruments_data()
        for inst in instruments:
            if inst.get("instId") == symbol:
                list_time = inst.get("listTime", "")
                if list_time:
                    list_time_int = int(list_time)
                    # ç¼“å­˜ç»“æœ
                    self._list_time_cache[symbol] = list_time_int
                    return list_time_int

        return None

    def convert_interval(self, interval: str) -> str:
        """è½¬æ¢å‘¨æœŸæ ¼å¼åˆ° OKX æ ¼å¼"""
        # Binance: 1m, 5m, 15m, 1h, 4h, 1d
        # OKX: 1m, 5m, 15m, 1H, 4H, 1D
        mapping = {
            "1m": "1m",
            "3m": "3m",
            "5m": "5m",
            "15m": "15m",
            "30m": "30m",
            "1h": "1H",
            "2h": "2H",
            "4h": "4H",
            "6h": "6H",
            "12h": "12H",
            "1d": "1D",
            "1w": "1W",
        }
        return mapping.get(interval.lower(), interval)

    def get_klines(self, symbol: str, interval: str, start_time: int, end_time: int, limit: int = 300) -> List[Dict]:
        """è·å– K çº¿æ•°æ®

        OKX API å®é™…è¡Œä¸ºï¼ˆç»è¿‡æµ‹è¯•éªŒè¯ï¼‰:
        - after=ts: è¿”å›æ—¶é—´æˆ³ < ts çš„æ•°æ®ï¼ˆå€’åºï¼Œæœ€æ–°çš„åœ¨å‰ï¼‰
        - before=ts: åœ¨æŸ¥è¯¢å†å²æ•°æ®æ—¶ä¼šè¢«å¿½ç•¥ï¼Œæ€»æ˜¯è¿”å›æœ€æ–°æ•°æ®

        ç­–ç•¥ï¼šä½¿ç”¨ after å‚æ•°ï¼Œä¼ å…¥ end_time + interval_msï¼Œè¿™æ ·å¯ä»¥è·å– <= end_time çš„æ•°æ®
        """
        url = f"{self.base_url}/api/v5/market/history-candles"
        okx_interval = self.convert_interval(interval)

        # ä½¿ç”¨ after å‚æ•°æ¥è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„æ•°æ®
        # after=ts å®é™…è¿”å›æ—¶é—´æˆ³ < ts çš„æ•°æ®ï¼ˆå€’åºï¼Œæœ€æ–°çš„åœ¨å‰ï¼‰
        # æ‰€ä»¥æˆ‘ä»¬ä¼ å…¥ end_time + interval_msï¼Œè¿™æ ·å¯ä»¥åŒ…å« end_time è¿™æ ¹Kçº¿
        interval_ms = interval_to_ms(interval)
        params = {
            "instId": symbol,
            "bar": okx_interval,
            "after": str(end_time + interval_ms),  # è·å– < end_time+interval çš„æ•°æ®
            "limit": str(min(limit, 300))
        }

        try:
            response = self.session.get(url, params=params, timeout=30)
            if response.status_code == 200:
                data = response.json()
                if data.get("code") == "0":
                    klines = []
                    # OKX è¿”å›çš„æ•°æ®æ˜¯å€’åºçš„ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰ï¼Œéœ€è¦åè½¬
                    raw_data = data.get("data", [])
                    for item in reversed(raw_data):
                        if len(item) >= 6:
                            ts = int(item[0])
                            # åªä¿ç•™åœ¨ [start_time, end_time] èŒƒå›´å†…çš„Kçº¿
                            if start_time <= ts <= end_time:
                                kline = {
                                    "timestamp": ts,
                                    "open": float(item[1]),
                                    "high": float(item[2]),
                                    "low": float(item[3]),
                                    "close": float(item[4]),
                                    "volume": float(item[5]),
                                    "symbol": symbol,
                                    "exchange": "okx",
                                    "interval": interval,
                                    "type": "kline"
                                }
                                klines.append(kline)
                    return klines
                else:
                    print(f"[OKX] {symbol} API é”™è¯¯: {data.get('msg', 'Unknown error')}")
            else:
                print(f"[OKX] {symbol} API è¿”å› {response.status_code}: {response.text[:100]}")
        except Exception as e:
            print(f"[OKX] {symbol} è·å– K çº¿å¤±è´¥: {e}")
        return []


class RedisKlineStorage:
    """Redis K çº¿æ•°æ®å­˜å‚¨"""

    def __init__(self, host: str = REDIS_HOST, port: int = REDIS_PORT, password: str = REDIS_PASSWORD):
        self.host = host
        self.port = port
        self.password = password
        self.client: Optional[redis.Redis] = None

    def connect(self) -> bool:
        """è¿æ¥åˆ° Redis"""
        try:
            self.client = redis.Redis(
                host=self.host,
                port=self.port,
                password=self.password if self.password else None,
                decode_responses=True
            )
            self.client.ping()
            print(f"[Redis] è¿æ¥æˆåŠŸ: {self.host}:{self.port}")
            return True
        except Exception as e:
            print(f"[Redis] è¿æ¥å¤±è´¥: {e}")
            return False

    def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        if self.client:
            self.client.close()
            self.client = None

    def store_klines(self, symbol: str, interval: str, exchange: str, klines: List[Dict]) -> int:
        """å­˜å‚¨ K çº¿æ•°æ®åˆ° Redisï¼ˆæ ¼å¼ä¸data_recorderå®Œå…¨ä¸€è‡´ï¼Œè‡ªåŠ¨å»é‡ï¼‰"""
        if not self.client or not klines:
            return 0

        key = f"kline:{exchange}:{symbol}:{interval}"

        try:
            # è·å–å·²å­˜åœ¨çš„æ—¶é—´æˆ³ï¼Œç”¨äºå»é‡
            existing_timestamps = set()
            try:
                all_data = self.client.zrange(key, 0, -1, withscores=True)
                existing_timestamps = {int(score) for _, score in all_data}
            except:
                pass

            # ä½¿ç”¨ pipeline æ‰¹é‡å†™å…¥ï¼Œè·³è¿‡å·²å­˜åœ¨çš„æ—¶é—´æˆ³
            pipe = self.client.pipeline()
            stored_count = 0

            for kline in klines:
                timestamp = kline["timestamp"]
                # åªå­˜å‚¨ä¸å­˜åœ¨çš„æ—¶é—´æˆ³
                if timestamp not in existing_timestamps:
                    value = json.dumps(kline)
                    pipe.zadd(key, {value: timestamp})
                    stored_count += 1
                    existing_timestamps.add(timestamp)  # æ›´æ–°å·²å­˜åœ¨é›†åˆ

            pipe.execute()
            return stored_count
        except Exception as e:
            print(f"[é”™è¯¯] å­˜å‚¨ {symbol} K çº¿å¤±è´¥: {e}")
            return 0

    def get_kline_count(self, symbol: str, interval: str, exchange: str) -> int:
        """è·å–å·²å­˜å‚¨çš„ K çº¿æ•°é‡"""
        if not self.client:
            return 0
        key = f"kline:{exchange}:{symbol}:{interval}"
        try:
            return self.client.zcard(key)
        except:
            return 0

    def get_latest_timestamp(self, symbol: str, interval: str, exchange: str) -> Optional[int]:
        """è·å–æœ€æ–°çš„ K çº¿æ—¶é—´æˆ³"""
        if not self.client:
            return None
        key = f"kline:{exchange}:{symbol}:{interval}"
        try:
            result = self.client.zrevrange(key, 0, 0, withscores=True)
            if result:
                return int(result[0][1])
        except:
            pass
        return None

    def get_oldest_timestamp(self, symbol: str, interval: str, exchange: str) -> Optional[int]:
        """è·å–æœ€æ—©çš„ K çº¿æ—¶é—´æˆ³"""
        if not self.client:
            return None
        key = f"kline:{exchange}:{symbol}:{interval}"
        try:
            result = self.client.zrange(key, 0, 0, withscores=True)
            if result:
                return int(result[0][1])
        except:
            pass
        return None

    def deduplicate_klines(self, symbol: str, interval: str, exchange: str) -> int:
        """
        å»é™¤é‡å¤çš„Kçº¿æ•°æ®

        å¯¹äºç›¸åŒæ—¶é—´æˆ³çš„Kçº¿ï¼Œåªä¿ç•™ä¸€æ¡ï¼ˆä¿ç•™æœ€åä¸€æ¡ï¼‰

        Returns:
            åˆ é™¤çš„é‡å¤æ•°æ®æ•°é‡
        """
        if not self.client:
            return 0

        key = f"kline:{exchange}:{symbol}:{interval}"

        try:
            # è·å–æ‰€æœ‰æ•°æ®
            all_data = self.client.zrange(key, 0, -1, withscores=True)

            if len(all_data) == 0:
                return 0

            # æŒ‰æ—¶é—´æˆ³åˆ†ç»„ï¼Œæ‰¾å‡ºé‡å¤çš„
            from collections import defaultdict
            timestamp_groups = defaultdict(list)

            for value, score in all_data:
                timestamp = int(score)
                timestamp_groups[timestamp].append(value)

            # ç»Ÿè®¡é‡å¤æ•°é‡
            duplicates_count = sum(len(values) - 1 for values in timestamp_groups.values() if len(values) > 1)

            if duplicates_count == 0:
                return 0

            # åˆ é™¤æ‰€æœ‰æ•°æ®ï¼Œç„¶åé‡æ–°æ’å…¥å»é‡åçš„æ•°æ®
            pipe = self.client.pipeline()

            # åˆ é™¤æ•´ä¸ªkey
            pipe.delete(key)

            # é‡æ–°æ’å…¥å»é‡åçš„æ•°æ®ï¼ˆæ¯ä¸ªæ—¶é—´æˆ³åªä¿ç•™æœ€åä¸€æ¡ï¼‰
            for timestamp, values in timestamp_groups.items():
                # åªä¿ç•™æœ€åä¸€æ¡
                value = values[-1]
                pipe.zadd(key, {value: timestamp})

            pipe.execute()

            return duplicates_count

        except Exception as e:
            print(f"[é”™è¯¯] å»é‡ {symbol} K çº¿å¤±è´¥: {e}")
            return 0

    def get_all_usdt_contracts(self) -> Dict[str, List[str]]:
        """
        ä»Redisæ‰«ææ‰€æœ‰USDTåˆçº¦

        Returns:
            {"okx": ["BTC-USDT-SWAP", ...], "binance": ["BTCUSDT", ...]}
        """
        if not self.client:
            return {}

        contracts = {"okx": [], "binance": []}

        try:
            # æ‰«ææ‰€æœ‰ kline:*:1m keys
            keys = self.client.keys("kline:*:1m")

            for key in keys:
                # keyæ ¼å¼: kline:exchange:symbol:1m
                parts = key.split(":")
                if len(parts) != 4:
                    continue

                exchange = parts[1]
                symbol = parts[2]

                # åªå¤„ç†USDTåˆçº¦
                if exchange == "okx" and "-USDT-SWAP" in symbol:
                    contracts["okx"].append(symbol)
                elif exchange == "binance" and symbol.endswith("USDT"):
                    contracts["binance"].append(symbol)

            # æ’åº
            contracts["okx"] = sorted(contracts["okx"])
            contracts["binance"] = sorted(contracts["binance"])

        except Exception as e:
            print(f"[Redis] æ‰«æåˆçº¦å¤±è´¥: {e}")

        return contracts


def interval_to_ms(interval: str) -> int:
    """å°†å‘¨æœŸè½¬æ¢ä¸ºæ¯«ç§’"""
    interval = interval.lower()
    unit = interval[-1]
    value = int(interval[:-1])

    if unit == 'm':
        return value * 60 * 1000
    elif unit == 'h':
        return value * 60 * 60 * 1000
    elif unit == 'd':
        return value * 24 * 60 * 60 * 1000
    elif unit == 'w':
        return value * 7 * 24 * 60 * 60 * 1000
    else:
        return value * 60 * 1000  # é»˜è®¤åˆ†é’Ÿ


def check_continuity(storage: RedisKlineStorage, symbol: str, interval: str, exchange: str) -> Dict:
    """
    æ£€æŸ¥Kçº¿æ•°æ®çš„è¿ç»­æ€§

    Args:
        storage: Rediså­˜å‚¨
        symbol: äº¤æ˜“å¯¹
        interval: Kçº¿å‘¨æœŸ
        exchange: äº¤æ˜“æ‰€

    Returns:
        åŒ…å«è¿ç»­æ€§ä¿¡æ¯çš„å­—å…¸
    """
    key = f"kline:{exchange}:{symbol}:{interval}"
    interval_ms = interval_to_ms(interval)

    try:
        # è·å–æ‰€æœ‰æ—¶é—´æˆ³
        all_data = storage.client.zrange(key, 0, -1, withscores=True)
        if not all_data:
            return {
                "continuous": False,
                "count": 0,
                "missing": 0,
                "time_range": None,
                "message": "æ— æ•°æ®"
            }

        timestamps = sorted([int(score) for _, score in all_data])
        count = len(timestamps)

        if count < 2:
            return {
                "continuous": True,
                "count": count,
                "missing": 0,
                "time_range": (timestamps[0], timestamps[0]),
                "message": "æ•°æ®ä¸è¶³2æ¡ï¼Œæ— æ³•æ£€æµ‹è¿ç»­æ€§"
            }

        # è®¡ç®—åº”æœ‰çš„Kçº¿æ•°é‡
        time_span_ms = timestamps[-1] - timestamps[0]
        expected_count = (time_span_ms // interval_ms) + 1
        missing_count = expected_count - count

        # æ£€æµ‹é—´éš”
        gaps = []
        for i in range(1, len(timestamps)):
            gap_ms = timestamps[i] - timestamps[i-1]
            if gap_ms > interval_ms * 1.5:  # å…è®¸ä¸€å®šè¯¯å·®
                gap_count = (gap_ms // interval_ms) - 1
                if gap_count > 0:
                    gaps.append({
                        'start': timestamps[i-1],
                        'end': timestamps[i],
                        'count': gap_count
                    })

        continuous = (missing_count == 0 and len(gaps) == 0)

        start_time = datetime.fromtimestamp(timestamps[0]/1000).strftime('%Y-%m-%d %H:%M:%S')
        end_time = datetime.fromtimestamp(timestamps[-1]/1000).strftime('%Y-%m-%d %H:%M:%S')

        if continuous:
            message = f"âœ“ è¿ç»­ ({count} æ ¹)"
        else:
            message = f"âœ— ç¼ºå¤± {missing_count} æ ¹ (åº”æœ‰ {expected_count} æ ¹)"

        return {
            "continuous": continuous,
            "count": count,
            "expected": expected_count,
            "missing": missing_count,
            "gaps": len(gaps),
            "time_range": (timestamps[0], timestamps[-1]),
            "time_range_str": f"{start_time} ~ {end_time}",
            "message": message
        }

    except Exception as e:
        return {
            "continuous": False,
            "count": 0,
            "missing": 0,
            "time_range": None,
            "message": f"æ£€æµ‹å¤±è´¥: {e}"
        }


def load_symbol_klines(
    loader: BaseKlineLoader,
    storage: RedisKlineStorage,
    symbol: str,
    interval: str,
    days: int
) -> int:
    """åŠ è½½å•ä¸ªäº¤æ˜“å¯¹çš„ K çº¿æ•°æ®"""
    total_loaded = 0
    interval_ms = interval_to_ms(interval)
    exchange = loader.exchange_name
    batch_size = loader.batch_size

    # è®¡ç®—æ—¶é—´èŒƒå›´
    end_time = int(datetime.now().timestamp() * 1000)
    start_time = end_time - days * 24 * 60 * 60 * 1000

    # ğŸ†• æ£€æŸ¥åˆçº¦ä¸Šçº¿æ—¶é—´ï¼Œå¦‚æœä¸Šçº¿æ—¶é—´æ™šäºè®¡ç®—çš„start_timeï¼Œåˆ™ä½¿ç”¨ä¸Šçº¿æ—¶é—´
    list_time = loader.get_symbol_list_time(symbol)
    if list_time:
        list_time_dt = datetime.fromtimestamp(list_time / 1000)
        original_start_dt = datetime.fromtimestamp(start_time / 1000)

        if list_time > start_time:
            # åˆçº¦ä¸Šçº¿æ—¶é—´æ™šäºè¯·æ±‚çš„å¼€å§‹æ—¶é—´ï¼Œä½¿ç”¨ä¸Šçº¿æ—¶é—´
            days_since_list = (end_time - list_time) / (24 * 60 * 60 * 1000)
            print(f"[{exchange}] {symbol} ä¸Šçº¿æ—¶é—´: {list_time_dt.strftime('%Y-%m-%d %H:%M:%S')} "
                  f"(è·ä»Š {days_since_list:.1f} å¤©ï¼Œå°‘äºè¯·æ±‚çš„ {days} å¤©)")
            print(f"[{exchange}] {symbol} è°ƒæ•´å¼€å§‹æ—¶é—´: {original_start_dt.strftime('%Y-%m-%d %H:%M:%S')} "
                  f"-> {list_time_dt.strftime('%Y-%m-%d %H:%M:%S')}")
            start_time = list_time
        else:
            # åˆçº¦ä¸Šçº¿æ—¶é—´æ—©äºè¯·æ±‚çš„å¼€å§‹æ—¶é—´ï¼Œæ­£å¸¸æ‹‰å–
            print(f"[{exchange}] {symbol} ä¸Šçº¿æ—¶é—´: {list_time_dt.strftime('%Y-%m-%d %H:%M:%S')} "
                  f"(æ—©äºè¯·æ±‚çš„ {days} å¤©ï¼Œæ­£å¸¸æ‹‰å–)")
    else:
        print(f"[{exchange}] {symbol} æ— æ³•è·å–ä¸Šçº¿æ—¶é—´ï¼Œä½¿ç”¨é»˜è®¤æ—¶é—´èŒƒå›´")

    # æ£€æŸ¥å·²æœ‰æ•°æ®
    existing_count = storage.get_kline_count(symbol, interval, exchange)
    latest_ts = storage.get_latest_timestamp(symbol, interval, exchange)
    oldest_ts = storage.get_oldest_timestamp(symbol, interval, exchange)

    # æ™ºèƒ½åŠ è½½ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦åŠ è½½æ›´æ—©çš„æ•°æ®æˆ–æ›´æ–°æœ€æ–°æ•°æ®
    need_load_old = True
    need_load_new = True

    if oldest_ts and oldest_ts <= start_time:
        need_load_old = False  # å·²æœ‰è¶³å¤Ÿæ—©çš„æ•°æ®

    if latest_ts:
        # åªåŠ è½½æœ€æ–°çš„ç¼ºå¤±æ•°æ®
        if latest_ts > end_time - interval_ms * 2:
            need_load_new = False  # æ•°æ®å·²æ˜¯æœ€æ–°

    if not need_load_old and not need_load_new:
        return 0  # æ•°æ®å·²å®Œæ•´

    # åŠ è½½æ›´æ—©çš„å†å²æ•°æ®
    if need_load_old and oldest_ts:
        # ç¡®ä¿ä¸ä¼šå°è¯•æ‹‰å–æ—©äºåˆçº¦ä¸Šçº¿æ—¶é—´çš„æ•°æ®
        if oldest_ts > start_time:
            current_end = oldest_ts - interval_ms
            current_start = max(start_time, current_end - batch_size * interval_ms)

            while current_start < current_end and current_start >= start_time:
                klines = loader.get_klines(symbol, interval, current_start, current_end, batch_size)

                if klines:
                    stored = storage.store_klines(symbol, interval, exchange, klines)
                    total_loaded += stored
                    current_end = klines[0]["timestamp"] - interval_ms
                    current_start = max(start_time, current_end - batch_size * interval_ms)
                else:
                    # å¦‚æœæ‹‰å–å¤±è´¥ï¼Œå¯èƒ½æ˜¯è¯·æ±‚çš„æ—¶é—´æ—©äºåˆçº¦ä¸Šçº¿æ—¶é—´
                    # å°è¯•è°ƒæ•´current_startï¼Œé¿å…ç»§ç»­è¯·æ±‚æ— æ•ˆæ•°æ®
                    print(f"[{exchange}] {symbol} æ‹‰å–å¤±è´¥ï¼Œå¯èƒ½è¯·æ±‚æ—¶é—´æ—©äºæ•°æ®èµ·å§‹æ—¶é—´ï¼Œåœæ­¢å‘å‰æ‹‰å–")
                    break

                # æ ¹æ®äº¤æ˜“æ‰€ç±»å‹ä½¿ç”¨ä¸åŒçš„å»¶è¿Ÿ
                delay = BINANCE_REQUEST_DELAY if exchange == 'binance' else REQUEST_DELAY
                time.sleep(delay)
        else:
            print(f"[{exchange}] {symbol} å·²æœ‰æ•°æ®çš„èµ·å§‹æ—¶é—´æ—©äºæˆ–ç­‰äºç›®æ ‡æ—¶é—´ï¼Œæ— éœ€å‘å‰æ‹‰å–")

    # åŠ è½½æœ€æ–°æ•°æ®
    if need_load_new:
        if latest_ts:
            current_start = latest_ts + interval_ms
        else:
            current_start = start_time

        while current_start < end_time:
            current_end = min(current_start + batch_size * interval_ms, end_time)

            klines = loader.get_klines(symbol, interval, current_start, current_end, batch_size)

            if klines:
                stored = storage.store_klines(symbol, interval, exchange, klines)
                total_loaded += stored
                current_start = klines[-1]["timestamp"] + interval_ms
            else:
                current_start = current_end

            # æ ¹æ®äº¤æ˜“æ‰€ç±»å‹ä½¿ç”¨ä¸åŒçš„å»¶è¿Ÿ
            delay = BINANCE_REQUEST_DELAY if exchange == 'binance' else REQUEST_DELAY
            time.sleep(delay)

    return total_loaded


def load_historical_before_oldest(
    loader: BaseKlineLoader,
    storage: RedisKlineStorage,
    symbol: str,
    interval: str,
    days: int
) -> int:
    """
    ä»æœ€æ—©çš„Kçº¿æ—¶é—´æˆ³å¾€å‰åŠ è½½å†å²æ•°æ®

    Args:
        loader: Kçº¿åŠ è½½å™¨
        storage: Rediså­˜å‚¨
        symbol: äº¤æ˜“å¯¹
        interval: Kçº¿å‘¨æœŸ
        days: å¾€å‰åŠ è½½çš„å¤©æ•°

    Returns:
        åŠ è½½çš„Kçº¿æ•°é‡
    """
    total_loaded = 0
    interval_ms = interval_to_ms(interval)
    exchange = loader.exchange_name
    batch_size = loader.batch_size

    # è·å–å½“å‰æœ€æ—©çš„Kçº¿æ—¶é—´æˆ³
    oldest_ts = storage.get_oldest_timestamp(symbol, interval, exchange)

    if not oldest_ts:
        print(f"[{exchange.upper()}] {symbol}:{interval} - Redisä¸­æ— æ•°æ®ï¼Œè·³è¿‡")
        return 0

    # è®¡ç®—ç›®æ ‡æ—¶é—´èŒƒå›´ï¼šä»æœ€æ—©æ—¶é—´æˆ³å¾€å‰æ¨dayså¤©
    end_time = oldest_ts - interval_ms  # ä»æœ€æ—©Kçº¿çš„å‰ä¸€æ ¹å¼€å§‹
    start_time = end_time - days * 24 * 60 * 60 * 1000

    print(f"[{exchange.upper()}] {symbol}:{interval}")
    print(f"  å½“å‰æœ€æ—©: {datetime.fromtimestamp(oldest_ts/1000).strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  ç›®æ ‡èŒƒå›´: {datetime.fromtimestamp(start_time/1000).strftime('%Y-%m-%d %H:%M:%S')} ~ {datetime.fromtimestamp(end_time/1000).strftime('%Y-%m-%d %H:%M:%S')}")

    # ä»end_timeå¾€å‰æ‰¹é‡æ‹‰å–
    current_end = end_time
    current_start = max(start_time, current_end - batch_size * interval_ms)

    while current_start < current_end and current_start >= start_time:
        klines = loader.get_klines(symbol, interval, current_start, current_end, batch_size)

        if klines:
            stored = storage.store_klines(symbol, interval, exchange, klines)
            total_loaded += stored
            print(f"  æ‹‰å–: {datetime.fromtimestamp(klines[0]['timestamp']/1000).strftime('%Y-%m-%d %H:%M:%S')} ~ {datetime.fromtimestamp(klines[-1]['timestamp']/1000).strftime('%Y-%m-%d %H:%M:%S')} (+{stored}æ ¹)")

            # æ›´æ–°èŒƒå›´ï¼Œç»§ç»­å¾€å‰æ‹‰å–
            current_end = klines[0]["timestamp"] - interval_ms
            current_start = max(start_time, current_end - batch_size * interval_ms)
        else:
            print(f"  æ‹‰å–å¤±è´¥ï¼Œåœæ­¢")
            break

        # æ ¹æ®äº¤æ˜“æ‰€ç±»å‹ä½¿ç”¨ä¸åŒçš„å»¶è¿Ÿ
        delay = BINANCE_REQUEST_DELAY if exchange == 'binance' else REQUEST_DELAY
        time.sleep(delay)

    if total_loaded > 0:
        print(f"  âœ“ å®Œæˆ: å…±åŠ è½½ {total_loaded} æ ¹Kçº¿")
    else:
        print(f"  æ— æ–°æ•°æ®")

    return total_loaded


def fill_gaps_in_existing_data(
    loader: BaseKlineLoader,
    storage: RedisKlineStorage,
    symbol: str,
    interval: str
) -> int:
    """
    å¡«è¡¥ç°æœ‰æ•°æ®ä¸­çš„é—´éš”

    Args:
        loader: Kçº¿åŠ è½½å™¨
        storage: Rediså­˜å‚¨
        symbol: äº¤æ˜“å¯¹
        interval: Kçº¿å‘¨æœŸ

    Returns:
        å¡«è¡¥çš„Kçº¿æ•°é‡
    """
    total_loaded = 0
    interval_ms = interval_to_ms(interval)
    exchange = loader.exchange_name
    batch_size = loader.batch_size

    # è·å–æ‰€æœ‰ç°æœ‰Kçº¿çš„æ—¶é—´æˆ³
    key = f"kline:{exchange}:{symbol}:{interval}"
    try:
        # è·å–æ‰€æœ‰æ—¶é—´æˆ³
        all_data = storage.client.zrange(key, 0, -1, withscores=True)
        if not all_data or len(all_data) < 2:
            return 0

        timestamps = sorted([int(score) for _, score in all_data])

        print(f"[{exchange.upper()}] {symbol}:{interval} - æ£€æµ‹é—´éš”")
        print(f"  ç°æœ‰Kçº¿æ•°: {len(timestamps)}")

        # æ£€æµ‹é—´éš”ï¼ˆå¤§äº2å€intervalçš„è§†ä¸ºé—´éš”ï¼‰
        gaps = []
        for i in range(1, len(timestamps)):
            gap_ms = timestamps[i] - timestamps[i-1]
            if gap_ms > interval_ms * 2:  # é—´éš”å¤§äº2å€å‘¨æœŸ
                gap_count = (gap_ms // interval_ms) - 1
                if gap_count > 0:
                    gaps.append({
                        'start': timestamps[i-1] + interval_ms,
                        'end': timestamps[i] - interval_ms,
                        'count': gap_count
                    })

        if not gaps:
            print(f"  âœ“ æ•°æ®è¿ç»­ï¼Œæ— éœ€å¡«è¡¥")
            return 0

        print(f"  å‘ç° {len(gaps)} ä¸ªé—´éš”ï¼Œå…±ç¼ºå¤± {sum(g['count'] for g in gaps)} æ ¹Kçº¿")

        # å¡«è¡¥æ¯ä¸ªé—´éš”
        for idx, gap in enumerate(gaps, 1):
            gap_start = gap['start']
            gap_end = gap['end']

            print(f"  [{idx}/{len(gaps)}] å¡«è¡¥é—´éš”: {datetime.fromtimestamp(gap_start/1000).strftime('%Y-%m-%d %H:%M:%S')} ~ {datetime.fromtimestamp(gap_end/1000).strftime('%Y-%m-%d %H:%M:%S')} ({gap['count']}æ ¹)")

            # åˆ†æ‰¹æ‹‰å–
            current_start = gap_start
            while current_start <= gap_end:
                current_end = min(current_start + (batch_size - 1) * interval_ms, gap_end)

                klines = loader.get_klines(symbol, interval, current_start, current_end, batch_size)

                if klines and len(klines) > 0:
                    stored = storage.store_klines(symbol, interval, exchange, klines)
                    total_loaded += stored
                    print(f"    æ‹‰å–: {datetime.fromtimestamp(klines[0]['timestamp']/1000).strftime('%H:%M:%S')} ~ {datetime.fromtimestamp(klines[-1]['timestamp']/1000).strftime('%H:%M:%S')} (+{stored}æ ¹)")

                    # æ›´æ–°èµ·å§‹ä½ç½®ï¼šä»æœ€åä¸€æ ¹Kçº¿çš„ä¸‹ä¸€æ ¹å¼€å§‹
                    last_ts = klines[-1]["timestamp"]
                    current_start = last_ts + interval_ms

                    # å¦‚æœå·²ç»è¶…è¿‡gap_endï¼Œé€€å‡ºå¾ªç¯
                    if last_ts >= gap_end:
                        break
                else:
                    print(f"    æ‹‰å–å¤±è´¥ï¼Œè·³è¿‡æ­¤é—´éš”")
                    break

                # æ ¹æ®äº¤æ˜“æ‰€ç±»å‹ä½¿ç”¨ä¸åŒçš„å»¶è¿Ÿ
                delay = BINANCE_REQUEST_DELAY if exchange == 'binance' else REQUEST_DELAY
                time.sleep(delay)

        if total_loaded > 0:
            print(f"  âœ“ å®Œæˆ: å…±å¡«è¡¥ {total_loaded} æ ¹Kçº¿")

    except Exception as e:
        print(f"  âœ— å¡«è¡¥å¤±è´¥: {e}")

    return total_loaded


def load_from_current_time(
    loader: BaseKlineLoader,
    storage: RedisKlineStorage,
    symbol: str,
    interval: str,
    days: int
) -> int:
    """
    ä»å½“å‰æ—¶é—´å¾€å‰æ‹‰å–æŒ‡å®šå¤©æ•°çš„Kçº¿æ•°æ®ï¼ˆæ™ºèƒ½æ£€æµ‹ï¼Œåªæ‹‰å–ç¼ºå¤±éƒ¨åˆ†ï¼‰

    Args:
        loader: Kçº¿åŠ è½½å™¨
        storage: Rediså­˜å‚¨
        symbol: äº¤æ˜“å¯¹
        interval: Kçº¿å‘¨æœŸ
        days: å¾€å‰æ‹‰å–çš„å¤©æ•°

    Returns:
        åŠ è½½çš„Kçº¿æ•°é‡
    """
    total_loaded = 0
    interval_ms = interval_to_ms(interval)
    exchange = loader.exchange_name
    batch_size = loader.batch_size

    # è®¡ç®—ç›®æ ‡æ—¶é—´èŒƒå›´ï¼šä»å½“å‰æ—¶é—´å¾€å‰æ¨dayså¤©ï¼Œå¯¹é½åˆ°intervalè¾¹ç•Œ
    current_time = int(time.time() * 1000)
    # å¯¹é½åˆ°intervalè¾¹ç•Œï¼ˆå‘ä¸‹å–æ•´ï¼‰
    end_time = (current_time // interval_ms) * interval_ms
    start_time = end_time - days * 24 * 60 * 60 * 1000

    # ğŸ†• æ£€æŸ¥åˆçº¦ä¸Šçº¿æ—¶é—´ï¼Œå¦‚æœä¸Šçº¿æ—¶é—´æ™šäºè®¡ç®—çš„start_timeï¼Œåˆ™ä½¿ç”¨ä¸Šçº¿æ—¶é—´
    list_time = loader.get_symbol_list_time(symbol)
    if list_time:
        list_time_dt = datetime.fromtimestamp(list_time / 1000)
        original_start_dt = datetime.fromtimestamp(start_time / 1000)

        if list_time > start_time:
            # åˆçº¦ä¸Šçº¿æ—¶é—´æ™šäºè¯·æ±‚çš„å¼€å§‹æ—¶é—´ï¼Œä½¿ç”¨ä¸Šçº¿æ—¶é—´
            days_since_list = (end_time - list_time) / (24 * 60 * 60 * 1000)
            print(f"  âš ï¸  åˆçº¦ä¸Šçº¿æ—¶é—´: {list_time_dt.strftime('%Y-%m-%d %H:%M:%S')} (è·ä»Š {days_since_list:.1f} å¤©)")
            print(f"  âš ï¸  è°ƒæ•´å¼€å§‹æ—¶é—´: {original_start_dt.strftime('%Y-%m-%d %H:%M:%S')} -> {list_time_dt.strftime('%Y-%m-%d %H:%M:%S')}")
            start_time = list_time
        else:
            # åˆçº¦ä¸Šçº¿æ—¶é—´æ—©äºè¯·æ±‚çš„å¼€å§‹æ—¶é—´ï¼Œæ­£å¸¸æ‹‰å–
            print(f"  â„¹ï¸  åˆçº¦ä¸Šçº¿æ—¶é—´: {list_time_dt.strftime('%Y-%m-%d %H:%M:%S')} (æ—©äºè¯·æ±‚çš„ {days} å¤©)")
    else:
        print(f"  âš ï¸  æ— æ³•è·å–ä¸Šçº¿æ—¶é—´ï¼Œä½¿ç”¨é»˜è®¤æ—¶é—´èŒƒå›´")

    print(f"  ç›®æ ‡èŒƒå›´: {datetime.fromtimestamp(start_time/1000).strftime('%Y-%m-%d %H:%M:%S')} ~ {datetime.fromtimestamp(end_time/1000).strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  ç›®æ ‡å¤©æ•°: {days} å¤©")

    # æ­¥éª¤1: åˆ é™¤è¶…å‡ºæ—¶é—´èŒƒå›´çš„æ—§æ•°æ®
    key = f"kline:{exchange}:{symbol}:{interval}"
    try:
        # åˆ é™¤æ—©äºstart_timeçš„æ•°æ®
        deleted_old = storage.client.zremrangebyscore(key, '-inf', start_time - 1)
        # åˆ é™¤æ™šäºend_timeçš„æ•°æ®ï¼ˆæœªæ¥æ•°æ®ï¼‰
        deleted_future = storage.client.zremrangebyscore(key, end_time + 1, '+inf')

        total_deleted = deleted_old + deleted_future
        if total_deleted > 0:
            print(f"  æ¸…ç†æ•°æ®: åˆ é™¤ {deleted_old} æ ¹æ—§æ•°æ®, {deleted_future} æ ¹æœªæ¥æ•°æ®")
    except Exception as e:
        print(f"  æ¸…ç†æ•°æ®å¤±è´¥: {e}")

    # æ­¥éª¤2: æ£€æµ‹ç°æœ‰æ•°æ®ï¼Œæ‰¾å‡ºç¼ºå¤±çš„æ—¶é—´æ®µ
    try:
        all_data = storage.client.zrangebyscore(key, start_time, end_time, withscores=True)
        existing_timestamps = set(int(score) for _, score in all_data)

        if len(existing_timestamps) > 0:
            print(f"  ç°æœ‰æ•°æ®: {len(existing_timestamps)} æ ¹Kçº¿")

        # è®¡ç®—åº”æœ‰çš„æ‰€æœ‰æ—¶é—´æˆ³
        expected_timestamps = set()
        current_ts = start_time
        while current_ts <= end_time:
            expected_timestamps.add(current_ts)
            current_ts += interval_ms

        # æ‰¾å‡ºç¼ºå¤±çš„æ—¶é—´æˆ³
        missing_timestamps = sorted(expected_timestamps - existing_timestamps)

        if len(missing_timestamps) == 0:
            print(f"  âœ“ æ•°æ®å®Œæ•´ï¼Œæ— éœ€æ‹‰å–")
            return 0

        print(f"  ç¼ºå¤±æ•°æ®: {len(missing_timestamps)} æ ¹Kçº¿")

        # å°†ç¼ºå¤±çš„æ—¶é—´æˆ³åˆå¹¶ä¸ºè¿ç»­çš„æ—¶é—´æ®µ
        gaps = []
        if missing_timestamps:
            gap_start = missing_timestamps[0]
            gap_end = missing_timestamps[0]

            for ts in missing_timestamps[1:]:
                if ts - gap_end <= interval_ms * 1.5:  # è¿ç»­
                    gap_end = ts
                else:  # æ–°çš„é—´éš”
                    gaps.append((gap_start, gap_end))
                    gap_start = ts
                    gap_end = ts

            gaps.append((gap_start, gap_end))

        print(f"  éœ€è¦æ‹‰å– {len(gaps)} ä¸ªæ—¶é—´æ®µ:")
        for idx, (gap_start, gap_end) in enumerate(gaps, 1):
            gap_count = len([ts for ts in missing_timestamps if gap_start <= ts <= gap_end])
            start_str = datetime.fromtimestamp(gap_start/1000).strftime('%Y-%m-%d %H:%M:%S')
            end_str = datetime.fromtimestamp(gap_end/1000).strftime('%Y-%m-%d %H:%M:%S')
            print(f"    [{idx}] {start_str} ~ {end_str} ({gap_count}æ ¹)")

        # æ­¥éª¤3: æ‰¹é‡æ‹‰å–ç¼ºå¤±çš„æ—¶é—´æ®µ
        for idx, (gap_start, gap_end) in enumerate(gaps, 1):
            gap_count = len([ts for ts in missing_timestamps if gap_start <= ts <= gap_end])
            start_str = datetime.fromtimestamp(gap_start/1000).strftime('%Y-%m-%d %H:%M:%S')
            end_str = datetime.fromtimestamp(gap_end/1000).strftime('%Y-%m-%d %H:%M:%S')

            # æ£€æŸ¥è¿™ä¸ªgapæ˜¯å¦åœ¨åˆçº¦ä¸Šçº¿æ—¶é—´ä¹‹å‰
            if list_time and gap_end < list_time:
                print(f"  [{idx}/{len(gaps)}] è·³è¿‡: {start_str} ~ {end_str} (æ—©äºåˆçº¦ä¸Šçº¿æ—¶é—´)")
                continue

            # å¦‚æœgapçš„å¼€å§‹æ—¶é—´æ—©äºåˆçº¦ä¸Šçº¿æ—¶é—´ï¼Œè°ƒæ•´ä¸ºä»ä¸Šçº¿æ—¶é—´å¼€å§‹
            if list_time and gap_start < list_time:
                original_start_str = start_str
                gap_start = list_time
                start_str = datetime.fromtimestamp(gap_start/1000).strftime('%Y-%m-%d %H:%M:%S')
                print(f"  [{idx}/{len(gaps)}] è°ƒæ•´èµ·å§‹: {original_start_str} -> {start_str}")

            print(f"  [{idx}/{len(gaps)}] å¼€å§‹æ‹‰å–: {start_str} ~ {end_str}")

            # åˆ†æ‰¹æ‹‰å–è¿™ä¸ªæ—¶é—´æ®µ
            current_start = gap_start
            batch_num = 0
            consecutive_failures = 0  # è¿ç»­å¤±è´¥è®¡æ•°
            max_consecutive_failures = 3  # æœ€å¤šå…è®¸3æ¬¡è¿ç»­å¤±è´¥

            while current_start <= gap_end:
                current_end = min(current_start + (batch_size - 1) * interval_ms, gap_end)
                batch_num += 1

                klines = loader.get_klines(symbol, interval, current_start, current_end, batch_size)

                if klines:
                    stored = storage.store_klines(symbol, interval, exchange, klines)
                    total_loaded += stored
                    batch_start_str = datetime.fromtimestamp(klines[0]['timestamp']/1000).strftime('%H:%M:%S')
                    batch_end_str = datetime.fromtimestamp(klines[-1]['timestamp']/1000).strftime('%H:%M:%S')
                    print(f"    æ‰¹æ¬¡{batch_num}: {batch_start_str} ~ {batch_end_str} (+{stored}æ ¹)")

                    consecutive_failures = 0  # é‡ç½®å¤±è´¥è®¡æ•°

                    current_start = klines[-1]["timestamp"] + interval_ms
                    if current_start > gap_end:
                        break
                else:
                    consecutive_failures += 1
                    print(f"    æ‰¹æ¬¡{batch_num}: æ‹‰å–å¤±è´¥ (è¿ç»­å¤±è´¥{consecutive_failures}æ¬¡)")

                    # å¦‚æœè¿ç»­å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œåœæ­¢è¿™ä¸ªgapçš„æ‹‰å–
                    if consecutive_failures >= max_consecutive_failures:
                        print(f"    è¿ç»­å¤±è´¥{max_consecutive_failures}æ¬¡ï¼Œåœæ­¢æ‹‰å–æ­¤æ—¶é—´æ®µ")
                        break

                    # å¦åˆ™è·³è¿‡è¿™ä¸ªæ‰¹æ¬¡ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
                    current_start = current_end + interval_ms

                # æ ¹æ®äº¤æ˜“æ‰€ç±»å‹ä½¿ç”¨ä¸åŒçš„å»¶è¿Ÿ
                delay = BINANCE_REQUEST_DELAY if exchange == 'binance' else REQUEST_DELAY
                time.sleep(delay)

        if total_loaded > 0:
            print(f"  âœ“ å®Œæˆ: å…±åŠ è½½ {total_loaded} æ ¹Kçº¿")

    except Exception as e:
        print(f"  âœ— å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    return total_loaded


def process_single_contract(
    loader: BaseKlineLoader,
    storage: RedisKlineStorage,
    symbol: str,
    interval: str,
    days: int,
    index: int,
    total: int
) -> tuple:
    """
    å¤„ç†å•ä¸ªåˆçº¦çš„æ•°æ®åŠ è½½å’Œè¿ç»­æ€§æ£€æµ‹

    Returns:
        (symbol, interval, loaded_count, continuity_result)
    """
    try:
        print(f"\n{'='*60}")
        print(f"[{index}/{total}] å¤„ç†åˆçº¦: {symbol} | å‘¨æœŸ: {interval}")
        print(f"{'='*60}")

        # æ­¥éª¤1: å»é‡ç°æœ‰æ•°æ®
        print(f"\n  ã€å»é‡æ£€æŸ¥ã€‘")
        dedup_count = storage.deduplicate_klines(symbol, interval, loader.exchange_name)
        if dedup_count > 0:
            print(f"  âœ“ åˆ é™¤é‡å¤æ•°æ®: {dedup_count} æ ¹")
        else:
            print(f"  âœ“ æ— é‡å¤æ•°æ®")

        # æ­¥éª¤2: ä»å½“å‰æ—¶é—´å¾€å‰åŠ è½½æ•°æ®
        loaded = load_from_current_time(
            loader, storage, symbol, interval, days
        )

        # æ­¥éª¤3: è¿ç»­æ€§æ£€æµ‹
        print(f"\n  ã€è¿ç»­æ€§æ£€æµ‹ã€‘")
        continuity = check_continuity(storage, symbol, interval, loader.exchange_name)
        print(f"  çŠ¶æ€: {continuity['message']}")
        if continuity['time_range_str']:
            print(f"  æ—¶é—´èŒƒå›´: {continuity['time_range_str']}")
        print(f"{'='*60}")

        return (symbol, interval, loaded, continuity)

    except Exception as e:
        print(f"  âœ— å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return (symbol, interval, 0, None)


def load_exchange_data(
    loader: BaseKlineLoader,
    storage: RedisKlineStorage,
    symbols: List[str],
    interval: str,
    days: int,
    workers: int
) -> tuple:
    """åŠ è½½å•ä¸ªäº¤æ˜“æ‰€çš„æ•°æ®"""
    exchange = loader.exchange_name
    print(f"\n[{exchange.upper()}] å¼€å§‹åŠ è½½ {len(symbols)} ä¸ªäº¤æ˜“å¯¹çš„ {days} å¤© {interval} K çº¿æ•°æ®...")

    start_time = time.time()
    total_klines = 0
    success_count = 0
    failed_symbols = []

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘åŠ è½½
    with ThreadPoolExecutor(max_workers=workers) as executor:
        futures = {}
        for symbol in symbols:
            future = executor.submit(
                load_symbol_klines,
                loader, storage, symbol, interval, days
            )
            futures[future] = symbol

        for i, future in enumerate(as_completed(futures)):
            symbol = futures[future]
            try:
                loaded = future.result()
                if loaded > 0:
                    total_klines += loaded
                    success_count += 1
                    print(f"[{exchange.upper()}] [{i+1}/{len(symbols)}] {symbol}: +{loaded} æ¡")
                else:
                    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
                    existing = storage.get_kline_count(symbol, interval, exchange)
                    if existing > 0:
                        success_count += 1
                        print(f"[{exchange.upper()}] [{i+1}/{len(symbols)}] {symbol}: å·²æ˜¯æœ€æ–° ({existing} æ¡)")
                    else:
                        failed_symbols.append(symbol)
                        print(f"[{exchange.upper()}] [{i+1}/{len(symbols)}] {symbol}: æ— æ•°æ®")
            except Exception as e:
                failed_symbols.append(symbol)
                print(f"[{exchange.upper()}] [{i+1}/{len(symbols)}] {symbol}: å¤±è´¥ - {e}")

    elapsed = time.time() - start_time
    return total_klines, success_count, failed_symbols, elapsed


def deduplicate_all_contracts(
    storage: RedisKlineStorage,
    exchange: str = "all",
    interval: str = "all",
    workers: int = MAX_WORKERS
) -> None:
    """
    æ‰¹é‡å»é‡æ‰€æœ‰åˆçº¦çš„Kçº¿æ•°æ®

    Args:
        storage: Rediså­˜å‚¨
        exchange: äº¤æ˜“æ‰€ (okx/binance/all)
        interval: Kçº¿å‘¨æœŸ (1m/5m/15m/30m/1h/all)
        workers: å¹¶å‘çº¿ç¨‹æ•°
    """
    print("=" * 60)
    print("       K çº¿æ•°æ®æ‰¹é‡å»é‡å·¥å…·")
    print("=" * 60)
    print()

    # è·å–æ‰€æœ‰åˆçº¦
    all_contracts = storage.get_all_usdt_contracts()

    # ç­›é€‰äº¤æ˜“æ‰€
    if exchange == "all":
        exchanges = list(all_contracts.keys())
    else:
        exchanges = [exchange] if exchange in all_contracts else []

    if not exchanges:
        print("æœªæ‰¾åˆ°ä»»ä½•åˆçº¦")
        return

    # ç¡®å®šè¦å¤„ç†çš„å‘¨æœŸ
    if interval == "all":
        intervals = ["1m", "5m", "15m", "30m", "1h"]
    else:
        intervals = [interval]

    total_dedup = 0
    total_processed = 0

    for exch in exchanges:
        symbols = all_contracts.get(exch, [])
        if not symbols:
            continue

        print(f"\n[{exch.upper()}] å¼€å§‹å»é‡ {len(symbols)} ä¸ªåˆçº¦...")

        for intv in intervals:
            print(f"\n  å‘¨æœŸ: {intv}")
            print(f"  {'='*56}")

            dedup_count = 0
            processed = 0

            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å»é‡
            with ThreadPoolExecutor(max_workers=workers) as executor:
                futures = {}
                for symbol in symbols:
                    future = executor.submit(
                        storage.deduplicate_klines,
                        symbol, intv, exch
                    )
                    futures[future] = symbol

                for i, future in enumerate(as_completed(futures)):
                    symbol = futures[future]
                    try:
                        removed = future.result()
                        processed += 1
                        if removed > 0:
                            dedup_count += removed
                            print(f"  [{i+1}/{len(symbols)}] {symbol}: åˆ é™¤ {removed} æ ¹é‡å¤æ•°æ®")
                        else:
                            # åªåœ¨æœ‰é‡å¤æ—¶æ‰æ‰“å°
                            pass
                    except Exception as e:
                        print(f"  [{i+1}/{len(symbols)}] {symbol}: å¤±è´¥ - {e}")

            if dedup_count > 0:
                print(f"  âœ“ {intv} å‘¨æœŸ: å…±åˆ é™¤ {dedup_count} æ ¹é‡å¤æ•°æ®")
            else:
                print(f"  âœ“ {intv} å‘¨æœŸ: æ— é‡å¤æ•°æ®")

            total_dedup += dedup_count
            total_processed += processed

    print(f"\n{'='*60}")
    print(f"å»é‡å®Œæˆ:")
    print(f"  å¤„ç†åˆçº¦æ•°: {total_processed}")
    print(f"  åˆ é™¤é‡å¤æ•°: {total_dedup} æ ¹")
    print(f"{'='*60}")


def main():
    parser = argparse.ArgumentParser(description="é¢„åŠ è½½ K çº¿æ•°æ®åˆ° Redis")
    parser.add_argument("--mode", type=str, default="current", choices=["auto", "manual", "current", "deduplicate"],
                        help="è¿è¡Œæ¨¡å¼: current=ä»å½“å‰æ—¶é—´å¾€å‰åŠ è½½(é»˜è®¤), auto=ä»Redisæœ€æ—©æ—¶é—´æˆ³å¾€å‰åŠ è½½, manual=æ‰‹åŠ¨æŒ‡å®šå‚æ•°, deduplicate=æ‰¹é‡å»é‡")
    parser.add_argument("--days", type=int, default=60, help="åŠ è½½å¤©æ•° (é»˜è®¤: 60)")
    parser.add_argument("--interval", type=str, default="1m", help="K çº¿å‘¨æœŸ (é»˜è®¤: 1m, deduplicateæ¨¡å¼å¯ç”¨all)")
    parser.add_argument("--exchange", type=str, default="all", choices=["binance", "okx", "all"],
                        help="äº¤æ˜“æ‰€ (é»˜è®¤: all)")
    parser.add_argument("--testnet", action="store_true", help="ä½¿ç”¨æµ‹è¯•ç½‘")
    parser.add_argument("--symbols", type=str, default="", help="æŒ‡å®šäº¤æ˜“å¯¹ï¼Œé€—å·åˆ†éš” (é»˜è®¤: å…¨éƒ¨)")
    parser.add_argument("--workers", type=int, default=MAX_WORKERS, help=f"å¹¶å‘çº¿ç¨‹æ•° (é»˜è®¤: {MAX_WORKERS})")
    parser.add_argument("--no-proxy", action="store_true", help="ä¸ä½¿ç”¨ä»£ç†")
    args = parser.parse_args()

    # å¦‚æœæ˜¯å»é‡æ¨¡å¼ï¼Œç›´æ¥æ‰§è¡Œå»é‡
    if args.mode == "deduplicate":
        storage = RedisKlineStorage()
        if not storage.connect():
            print("Redisè¿æ¥å¤±è´¥ï¼Œé€€å‡º")
            return

        deduplicate_all_contracts(
            storage,
            exchange=args.exchange,
            interval=args.interval,
            workers=args.workers
        )
        return

    print("=" * 60)
    print("       K çº¿æ•°æ®é¢„åŠ è½½å·¥å…·")
    print("=" * 60)
    print()
    print(f"  æ¨¡å¼: {args.mode.upper()}")
    print(f"  äº¤æ˜“æ‰€: {args.exchange.upper()}")
    print(f"  ç½‘ç»œ: {'æµ‹è¯•ç½‘' if args.testnet else 'ä¸»ç½‘'}")
    print(f"  å¹¶å‘: {args.workers} çº¿ç¨‹")
    print(f"  ä»£ç†: {'ç¦ç”¨' if args.no_proxy else 'å¯ç”¨'}")
    print(f"  Redis: {REDIS_HOST}:{REDIS_PORT}")
    print()

    if args.mode == "current":
        print("  å½“å‰æ—¶é—´æ¨¡å¼è¯´æ˜:")
        print("  - ä»Redisæ‰«ææ‰€æœ‰USDTåˆçº¦")
        print("  - ä»å½“å‰æ—¶é—´å¾€å‰åŠ è½½:")
        print("    * 1m/5m/15m/30m: 2ä¸ªæœˆ")
        print("    * 1h: 6ä¸ªæœˆ")
        print("  - æ¯ä¸ªåˆçº¦åŠ è½½å®Œæˆåè¿›è¡Œè¿ç»­æ€§æ£€æµ‹")
    elif args.mode == "auto":
        print("  è‡ªåŠ¨æ¨¡å¼è¯´æ˜:")
        print("  - ä»Redisæ‰«ææ‰€æœ‰USDTåˆçº¦")
        print("  - æ£€æµ‹æ¯ä¸ªåˆçº¦çš„æœ€æ—©1min Kçº¿æ—¶é—´æˆ³")
        print("  - ä»æœ€æ—©æ—¶é—´æˆ³å¾€å‰åŠ è½½:")
        print("    * 1m/5m/15m/30m: 2ä¸ªæœˆ")
        print("    * 1h: 6ä¸ªæœˆ")
    else:
        print(f"  æ‰‹åŠ¨æ¨¡å¼: {args.days} å¤©, {args.interval}")

    print()
    print("-" * 60)

    # åˆå§‹åŒ– Redis
    storage = RedisKlineStorage()
    if not storage.connect():
        print("[é”™è¯¯] Redis è¿æ¥å¤±è´¥ï¼Œé€€å‡º")
        return 1

    use_proxy = not args.no_proxy
    results = {}

    # ==================== å½“å‰æ—¶é—´æ¨¡å¼ ====================
    if args.mode == "current":
        print("\n[å½“å‰æ—¶é—´æ¨¡å¼] ä»Redisæ‰«æUSDTåˆçº¦...")

        # è·å–æ‰€æœ‰USDTåˆçº¦
        contracts = storage.get_all_usdt_contracts()

        if not contracts["okx"] and not contracts["binance"]:
            print("[é”™è¯¯] Redisä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•USDTåˆçº¦æ•°æ®")
            print("[æç¤º] è¯·å…ˆè¿è¡Œ trading_server_full å’Œ data_recorder æ”¶é›†å®æ—¶æ•°æ®")
            return 1

        print(f"\n[æ‰«æç»“æœ]")
        print(f"  OKX: {len(contracts['okx'])} ä¸ªåˆçº¦")
        print(f"  Binance: {len(contracts['binance'])} ä¸ªåˆçº¦")

        # å®šä¹‰è¦åŠ è½½çš„å‘¨æœŸå’Œå¯¹åº”çš„å¤©æ•°
        intervals_config = [
            ("1m", 60),    # 2ä¸ªæœˆ
            ("5m", 60),    # 2ä¸ªæœˆ
            ("15m", 60),   # 2ä¸ªæœˆ
            ("30m", 60),   # 2ä¸ªæœˆ
            ("1h", 180),   # 6ä¸ªæœˆ
        ]

        # åŠ è½½ OKX æ•°æ®
        if contracts["okx"] and args.exchange in ["okx", "all"]:
            loader = OKXKlineLoader(testnet=args.testnet, use_proxy=use_proxy)

            for interval, days in intervals_config:
                print(f"\n{'='*60}")
                print(f"[OKX] å¤„ç† {interval} Kçº¿ (ä»å½“å‰æ—¶é—´å¾€å‰ {days} å¤©)")
                print(f"{'='*60}")

                total_loaded = 0
                success_count = 0

                # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
                with ThreadPoolExecutor(max_workers=args.workers) as executor:
                    futures = []
                    for i, symbol in enumerate(contracts["okx"], 1):
                        future = executor.submit(
                            process_single_contract,
                            loader, storage, symbol, interval, days, i, len(contracts["okx"])
                        )
                        futures.append(future)

                    # æ”¶é›†ç»“æœ
                    for future in as_completed(futures):
                        _, _, loaded, _ = future.result()
                        total_loaded += loaded
                        if loaded > 0:
                            success_count += 1

                print(f"\n[OKX {interval}] å®Œæˆ: {success_count}/{len(contracts['okx'])} ä¸ªåˆçº¦")
                print(f"  æ€»è®¡åŠ è½½: {total_loaded} æ ¹Kçº¿")

        # åŠ è½½ Binance æ•°æ®
        if contracts["binance"] and args.exchange in ["binance", "all"]:
            loader = BinanceKlineLoader(testnet=args.testnet, use_proxy=use_proxy)

            for interval, days in intervals_config:
                print(f"\n{'='*60}")
                print(f"[Binance] å¤„ç† {interval} Kçº¿ (ä»å½“å‰æ—¶é—´å¾€å‰ {days} å¤©)")
                print(f"{'='*60}")

                total_loaded = 0
                success_count = 0

                # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
                with ThreadPoolExecutor(max_workers=args.workers) as executor:
                    futures = []
                    for i, symbol in enumerate(contracts["binance"], 1):
                        future = executor.submit(
                            process_single_contract,
                            loader, storage, symbol, interval, days, i, len(contracts["binance"])
                        )
                        futures.append(future)

                    # æ”¶é›†ç»“æœ
                    for future in as_completed(futures):
                        _, _, loaded, _ = future.result()
                        total_loaded += loaded
                        if loaded > 0:
                            success_count += 1

                print(f"\n[Binance {interval}] å®Œæˆ: {success_count}/{len(contracts['binance'])} ä¸ªåˆçº¦")
                print(f"  æ€»è®¡åŠ è½½: {total_loaded} æ ¹Kçº¿")

        print()
        print("=" * 60)
        print("       å½“å‰æ—¶é—´æ¨¡å¼åŠ è½½å®Œæˆ")
        print("=" * 60)
        storage.disconnect()
        return 0

    # ==================== è‡ªåŠ¨æ¨¡å¼ ====================
    if args.mode == "auto":
        print("\n[è‡ªåŠ¨æ¨¡å¼] ä»Redisæ‰«æUSDTåˆçº¦...")

        # è·å–æ‰€æœ‰USDTåˆçº¦
        contracts = storage.get_all_usdt_contracts()

        if not contracts["okx"] and not contracts["binance"]:
            print("[é”™è¯¯] Redisä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•USDTåˆçº¦æ•°æ®")
            print("[æç¤º] è¯·å…ˆè¿è¡Œ trading_server_full å’Œ data_recorder æ”¶é›†å®æ—¶æ•°æ®")
            return 1

        print(f"\n[æ‰«æç»“æœ]")
        print(f"  OKX: {len(contracts['okx'])} ä¸ªåˆçº¦")
        print(f"  Binance: {len(contracts['binance'])} ä¸ªåˆçº¦")

        # å®šä¹‰è¦åŠ è½½çš„å‘¨æœŸå’Œå¯¹åº”çš„å¤©æ•°
        intervals_config = [
            ("1m", 60),    # 2ä¸ªæœˆ
            ("5m", 60),    # 2ä¸ªæœˆ
            ("15m", 60),   # 2ä¸ªæœˆ
            ("30m", 60),   # 2ä¸ªæœˆ
            ("1h", 180),   # 6ä¸ªæœˆ
        ]

        # åŠ è½½ OKX æ•°æ®
        if contracts["okx"] and args.exchange in ["okx", "all"]:
            loader = OKXKlineLoader(testnet=args.testnet, use_proxy=use_proxy)

            for interval, days in intervals_config:
                print(f"\n{'='*60}")
                print(f"[OKX] å¤„ç† {interval} Kçº¿")
                print(f"{'='*60}")

                total_loaded = 0
                total_filled = 0
                success_count = 0

                for i, symbol in enumerate(contracts["okx"], 1):
                    print(f"\n[{i}/{len(contracts['okx'])}] {symbol}:{interval}")

                    try:
                        # æ­¥éª¤1: å¡«è¡¥ç°æœ‰æ•°æ®çš„é—´éš”
                        filled = fill_gaps_in_existing_data(loader, storage, symbol, interval)
                        total_filled += filled

                        # æ­¥éª¤2: ä»æœ€æ—©æ—¶é—´æˆ³å¾€å‰åŠ è½½å†å²æ•°æ®
                        loaded = load_historical_before_oldest(
                            loader, storage, symbol, interval, days
                        )
                        total_loaded += loaded

                        if filled > 0 or loaded > 0:
                            success_count += 1
                    except Exception as e:
                        print(f"  âœ— å¤±è´¥: {e}")

                print(f"\n[OKX {interval}] å®Œæˆ: {success_count}/{len(contracts['okx'])} ä¸ªåˆçº¦")
                print(f"  å¡«è¡¥é—´éš”: {total_filled} æ ¹Kçº¿")
                print(f"  å†å²æ•°æ®: {total_loaded} æ ¹Kçº¿")
                print(f"  æ€»è®¡: {total_filled + total_loaded} æ ¹Kçº¿")

        # åŠ è½½ Binance æ•°æ®
        if contracts["binance"] and args.exchange in ["binance", "all"]:
            loader = BinanceKlineLoader(testnet=args.testnet, use_proxy=use_proxy)

            for interval, days in intervals_config:
                print(f"\n{'='*60}")
                print(f"[Binance] å¤„ç† {interval} Kçº¿")
                print(f"{'='*60}")

                total_loaded = 0
                total_filled = 0
                success_count = 0

                for i, symbol in enumerate(contracts["binance"], 1):
                    print(f"\n[{i}/{len(contracts['binance'])}] {symbol}:{interval}")

                    try:
                        # æ­¥éª¤1: å¡«è¡¥ç°æœ‰æ•°æ®çš„é—´éš”
                        filled = fill_gaps_in_existing_data(loader, storage, symbol, interval)
                        total_filled += filled

                        # æ­¥éª¤2: ä»æœ€æ—©æ—¶é—´æˆ³å¾€å‰åŠ è½½å†å²æ•°æ®
                        loaded = load_historical_before_oldest(
                            loader, storage, symbol, interval, days
                        )
                        total_loaded += loaded

                        if filled > 0 or loaded > 0:
                            success_count += 1
                    except Exception as e:
                        print(f"  âœ— å¤±è´¥: {e}")

                print(f"\n[Binance {interval}] å®Œæˆ: {success_count}/{len(contracts['binance'])} ä¸ªåˆçº¦")
                print(f"  å¡«è¡¥é—´éš”: {total_filled} æ ¹Kçº¿")
                print(f"  å†å²æ•°æ®: {total_loaded} æ ¹Kçº¿")
                print(f"  æ€»è®¡: {total_filled + total_loaded} æ ¹Kçº¿")

        print()
        print("=" * 60)
        print("       è‡ªåŠ¨åŠ è½½å®Œæˆ")
        print("=" * 60)
        storage.disconnect()
        return 0

    # ==================== æ‰‹åŠ¨æ¨¡å¼ ====================

    # åŠ è½½ Binance æ•°æ®
    if args.exchange in ["binance", "all"]:
        loader = BinanceKlineLoader(testnet=args.testnet, use_proxy=use_proxy)

        if args.symbols:
            symbols = [s.strip().upper() for s in args.symbols.split(",")]
            # ç¡®ä¿æ˜¯ Binance æ ¼å¼
            symbols = [s.replace("-", "").replace("SWAP", "") for s in symbols]
            if symbols[0].endswith("USDT"):
                pass  # å·²ç»æ˜¯ Binance æ ¼å¼
            print(f"[Binance] ä½¿ç”¨æŒ‡å®šçš„ {len(symbols)} ä¸ªäº¤æ˜“å¯¹")
        else:
            print("[Binance] è·å–äº¤æ˜“å¯¹åˆ—è¡¨...")
            symbols = loader.get_exchange_info()
            print(f"[Binance] è·å–åˆ° {len(symbols)} ä¸ªæ°¸ç»­åˆçº¦äº¤æ˜“å¯¹")

        if symbols:
            total, success, failed, elapsed = load_exchange_data(
                loader, storage, symbols, args.interval, args.days, args.workers
            )
            results["binance"] = {
                "total": total,
                "success": success,
                "failed": failed,
                "elapsed": elapsed,
                "symbols": symbols
            }

    # åŠ è½½ OKX æ•°æ®
    if args.exchange in ["okx", "all"]:
        loader = OKXKlineLoader(testnet=args.testnet, use_proxy=use_proxy)

        if args.symbols:
            symbols = [s.strip().upper() for s in args.symbols.split(",")]
            # è½¬æ¢ä¸º OKX æ ¼å¼
            okx_symbols = []
            for s in symbols:
                if "-SWAP" in s:
                    okx_symbols.append(s)
                elif s.endswith("USDT"):
                    base = s[:-4]
                    okx_symbols.append(f"{base}-USDT-SWAP")
                else:
                    okx_symbols.append(s)
            symbols = okx_symbols
            print(f"[OKX] ä½¿ç”¨æŒ‡å®šçš„ {len(symbols)} ä¸ªäº¤æ˜“å¯¹")
        else:
            print("[OKX] è·å–äº¤æ˜“å¯¹åˆ—è¡¨...")
            symbols = loader.get_exchange_info()
            print(f"[OKX] è·å–åˆ° {len(symbols)} ä¸ªæ°¸ç»­åˆçº¦äº¤æ˜“å¯¹")

        if symbols:
            total, success, failed, elapsed = load_exchange_data(
                loader, storage, symbols, args.interval, args.days, args.workers
            )
            results["okx"] = {
                "total": total,
                "success": success,
                "failed": failed,
                "elapsed": elapsed,
                "symbols": symbols
            }

    # ç»Ÿè®¡ç»“æœ
    print()
    print("=" * 60)
    print("       åŠ è½½å®Œæˆ")
    print("=" * 60)

    for exchange, data in results.items():
        print()
        print(f"[{exchange.upper()}]")
        print(f"  æ€»è€—æ—¶: {data['elapsed']:.1f} ç§’")
        print(f"  æˆåŠŸ: {data['success']}/{len(data['symbols'])} ä¸ªäº¤æ˜“å¯¹")
        print(f"  æ–°å¢: {data['total']} æ¡ K çº¿")
        if data['failed']:
            print(f"  å¤±è´¥: {len(data['failed'])} ä¸ª")
            print(f"  å¤±è´¥åˆ—è¡¨: {data['failed'][:5]}{'...' if len(data['failed']) > 5 else ''}")

    # æ˜¾ç¤ºéƒ¨åˆ†äº¤æ˜“å¯¹çš„æ•°æ®é‡
    print()
    print("[æ•°æ®ç»Ÿè®¡]")

    if "binance" in results:
        sample_symbols = ["BTCUSDT", "ETHUSDT", "SOLUSDT", "BNBUSDT", "XRPUSDT"]
        print("  Binance:")
        for sym in sample_symbols:
            count = storage.get_kline_count(sym, args.interval, "binance")
            if count > 0:
                print(f"    {sym}: {count} æ¡")

    if "okx" in results:
        sample_symbols = ["BTC-USDT-SWAP", "ETH-USDT-SWAP", "SOL-USDT-SWAP", "DOGE-USDT-SWAP", "XRP-USDT-SWAP"]
        print("  OKX:")
        for sym in sample_symbols:
            count = storage.get_kline_count(sym, args.interval, "okx")
            if count > 0:
                print(f"    {sym}: {count} æ¡")

    storage.disconnect()
    print()
    print("[å®Œæˆ] æ•°æ®å·²å­˜å‚¨åˆ° Redis")
    return 0


if __name__ == "__main__":
    sys.exit(main())
